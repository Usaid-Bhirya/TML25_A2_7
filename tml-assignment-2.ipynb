{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:07:14.229791Z",
     "iopub.status.busy": "2025-06-24T20:07:14.229439Z",
     "iopub.status.idle": "2025-06-24T20:07:17.442379Z",
     "shell.execute_reply": "2025-06-24T20:07:17.441282Z",
     "shell.execute_reply.started": "2025-06-24T20:07:14.229767Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:07:20.186515Z",
     "iopub.status.busy": "2025-06-24T20:07:20.186174Z",
     "iopub.status.idle": "2025-06-24T20:07:20.191704Z",
     "shell.execute_reply": "2025-06-24T20:07:20.191046Z",
     "shell.execute_reply.started": "2025-06-24T20:07:20.186485Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import requests\n",
    "import base64\n",
    "import io\n",
    "from datetime import datetime\n",
    "import onnxruntime as ort\n",
    "from typing import Tuple\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:37:48.625368Z",
     "iopub.status.busy": "2025-06-24T20:37:48.624582Z",
     "iopub.status.idle": "2025-06-24T20:37:48.667662Z",
     "shell.execute_reply": "2025-06-24T20:37:48.666924Z",
     "shell.execute_reply.started": "2025-06-24T20:37:48.625337Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class TaskDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        self.ids = []\n",
    "        self.imgs = []\n",
    "        self.labels = []\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index) -> Tuple[int, torch.Tensor, int]:\n",
    "        id_ = self.ids[index]\n",
    "        img = self.imgs[index]\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        label = self.labels[index]\n",
    "        return id_, img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "class ImprovedStolenEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=3, output_dim=1024):\n",
    "        super(ImprovedStolenEncoder, self).__init__()\n",
    "        \n",
    "        # More sophisticated feature extraction with residual connections\n",
    "        self.initial_conv = nn.Sequential(\n",
    "            nn.Conv2d(input_dim, 64, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # Residual blocks with different channel sizes\n",
    "        self.res_block1 = self._make_residual_block(64, 128, stride=2)\n",
    "        self.res_block2 = self._make_residual_block(128, 256, stride=2)\n",
    "        self.res_block3 = self._make_residual_block(256, 512, stride=2)\n",
    "        self.res_block4 = self._make_residual_block(512, 512, stride=2)\n",
    "        \n",
    "        # Replace AdaptiveAvgPool2d with regular pooling for ONNX compatibility\n",
    "        # After 4 stride-2 operations: 32->16->8->4->2, so final size is 2x2\n",
    "        self.global_pool = nn.AvgPool2d(kernel_size=2, stride=1)  # 2x2 -> 1x1\n",
    "        \n",
    "        # More sophisticated projection head with dropout and residual connection\n",
    "        self.projection_head = nn.Sequential(\n",
    "            nn.Linear(512, 2048, bias=False),\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(2048, 1024, bias=False),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(1024, output_dim)\n",
    "        )\n",
    "        \n",
    "        # Initialize weights properly\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _make_residual_block(self, in_channels, out_channels, stride=1):\n",
    "        \"\"\"Create a residual block with proper skip connections\"\"\"\n",
    "        layers = []\n",
    "        \n",
    "        # Main path\n",
    "        layers.extend([\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        ])\n",
    "        \n",
    "        main_path = nn.Sequential(*layers)\n",
    "        \n",
    "        # Skip connection\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            skip_connection = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            skip_connection = nn.Identity()\n",
    "        \n",
    "        return ResidualBlock(main_path, skip_connection)\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        \"\"\"Initialize weights using He initialization\"\"\"\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initial convolution\n",
    "        x = self.initial_conv(x)\n",
    "        \n",
    "        # Residual blocks\n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "        x = self.res_block3(x)\n",
    "        x = self.res_block4(x)\n",
    "        \n",
    "        # Global pooling - ONNX compatible\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        \n",
    "        # Projection head\n",
    "        x = self.projection_head(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Custom residual block for better ONNX compatibility\"\"\"\n",
    "    def __init__(self, main_path, skip_connection):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.main_path = main_path\n",
    "        self.skip_connection = skip_connection\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = self.skip_connection(x)\n",
    "        out = self.main_path(x)\n",
    "        out = out + identity\n",
    "        return F.relu(out, inplace=True)\n",
    "\n",
    "class B4BRobustTrainer:\n",
    "    def __init__(self, model, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "        self.model = model.to(device)\n",
    "        self.device = device\n",
    "        print(f\"Using device: {device}\")\n",
    "        \n",
    "    def create_dataloader(self, images, representations, batch_size=64, test_split=0.2):\n",
    "        \"\"\"Create dataloaders with improved data preprocessing\"\"\"\n",
    "        print(\"Creating dataloaders with enhanced preprocessing...\")\n",
    "        \n",
    "        # Determine image type\n",
    "        sample_img = images[0]\n",
    "        if hasattr(sample_img, 'mode'):\n",
    "            is_grayscale = sample_img.mode == 'L'\n",
    "        else:\n",
    "            if isinstance(sample_img, torch.Tensor):\n",
    "                is_grayscale = sample_img.shape[0] == 1\n",
    "            else:\n",
    "                from PIL import Image\n",
    "                if isinstance(sample_img, Image.Image):\n",
    "                    is_grayscale = sample_img.mode == 'L'\n",
    "                else:\n",
    "                    is_grayscale = len(sample_img.shape) == 2 or sample_img.shape[-1] == 1\n",
    "        \n",
    "        print(f\"Images are {'grayscale' if is_grayscale else 'RGB'}\")\n",
    "        \n",
    "        # Simple approach - always ensure 3 channels\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=10),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "            transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "        \n",
    "        val_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "        indices = list(range(len(images)))\n",
    "        train_indices, val_indices = train_test_split(indices, test_size=test_split, random_state=42)\n",
    "\n",
    "        train_image_tensors = []\n",
    "        val_image_tensors = []\n",
    "        \n",
    "        # Process training images\n",
    "        for i in train_indices:\n",
    "            img = images[i]\n",
    "            # Convert tensor to PIL if necessary\n",
    "            if isinstance(img, torch.Tensor):\n",
    "                if img.dim() == 3 and img.shape[0] in [1, 3]:\n",
    "                    img = transforms.ToPILImage()(img)\n",
    "                elif img.dim() == 2:\n",
    "                    img = transforms.ToPILImage()(img.unsqueeze(0))\n",
    "            \n",
    "            img_tensor = train_transform(img)\n",
    "            # Ensure 3 channels\n",
    "            if img_tensor.shape[0] == 1:\n",
    "                img_tensor = img_tensor.repeat(3, 1, 1)\n",
    "            # Apply normalization after ensuring 3 channels\n",
    "            img_tensor = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img_tensor)\n",
    "            train_image_tensors.append(img_tensor)\n",
    "            \n",
    "        # Process validation images\n",
    "        for i in val_indices:\n",
    "            img = images[i]\n",
    "            # Convert tensor to PIL if necessary\n",
    "            if isinstance(img, torch.Tensor):\n",
    "                if img.dim() == 3 and img.shape[0] in [1, 3]:\n",
    "                    img = transforms.ToPILImage()(img)\n",
    "                elif img.dim() == 2:\n",
    "                    img = transforms.ToPILImage()(img.unsqueeze(0))\n",
    "            \n",
    "            img_tensor = val_transform(img)\n",
    "            # Ensure 3 channels\n",
    "            if img_tensor.shape[0] == 1:\n",
    "                img_tensor = img_tensor.repeat(3, 1, 1)\n",
    "            # Apply normalization after ensuring 3 channels\n",
    "            img_tensor = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(img_tensor)\n",
    "            val_image_tensors.append(img_tensor)\n",
    "        \n",
    "        # Stack tensors and split representations\n",
    "        X_train = torch.stack(train_image_tensors)\n",
    "        X_val = torch.stack(val_image_tensors)\n",
    "        y_train = torch.tensor([representations[i] for i in train_indices], dtype=torch.float32)\n",
    "        y_val = torch.tensor([representations[i] for i in val_indices], dtype=torch.float32)\n",
    "        \n",
    "        print(f\"Data shapes: Train Images {X_train.shape}, Train Representations {y_train.shape}\")\n",
    "        print(f\"             Val Images {X_val.shape}, Val Representations {y_val.shape}\")\n",
    "        \n",
    "        # Create datasets\n",
    "        train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "        val_dataset = torch.utils.data.TensorDataset(X_val, y_val)\n",
    "        \n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                                num_workers=4, pin_memory=True, drop_last=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, \n",
    "                              num_workers=4, pin_memory=True)\n",
    "        \n",
    "        print(f\"Training samples: {len(train_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "        return train_loader, val_loader\n",
    "    \n",
    "    def advanced_loss_function(self, predictions, targets, epoch=0):\n",
    "        \"\"\"Advanced loss function specifically designed for B4B defense\"\"\"\n",
    "        \n",
    "        # Standard MSE loss\n",
    "        mse_loss = F.mse_loss(predictions, targets)\n",
    "        \n",
    "        # Cosine similarity loss (robust to scale differences)\n",
    "        cosine_loss = 1 - F.cosine_similarity(predictions, targets).mean()\n",
    "        \n",
    "        # Huber loss for robustness to outliers (B4B noise)\n",
    "        huber_loss = F.smooth_l1_loss(predictions, targets, beta=0.1)\n",
    "        \n",
    "        # L1 loss for sparsity\n",
    "        l1_loss = F.l1_loss(predictions, targets)\n",
    "        \n",
    "        # Correlation loss to maintain relationship structure\n",
    "        pred_centered = predictions - predictions.mean(dim=1, keepdim=True)\n",
    "        target_centered = targets - targets.mean(dim=1, keepdim=True)\n",
    "        correlation = (pred_centered * target_centered).sum(dim=1) / (\n",
    "            torch.sqrt((pred_centered ** 2).sum(dim=1)) * torch.sqrt((target_centered ** 2).sum(dim=1)) + 1e-8\n",
    "        )\n",
    "        correlation_loss = 1 - correlation.mean()\n",
    "        \n",
    "        # Adaptive weighting based on training progress\n",
    "        epoch_weight = min(epoch / 50.0, 1.0)  # Gradually increase correlation weight\n",
    "        \n",
    "        total_loss = (0.4 * mse_loss + \n",
    "                     0.2 * cosine_loss + \n",
    "                     0.2 * huber_loss + \n",
    "                     0.1 * l1_loss + \n",
    "                     0.1 * epoch_weight * correlation_loss)\n",
    "        \n",
    "        return total_loss, {\n",
    "            'mse': mse_loss.item(),\n",
    "            'cosine': cosine_loss.item(),\n",
    "            'huber': huber_loss.item(),\n",
    "            'l1': l1_loss.item(),\n",
    "            'correlation': correlation_loss.item()\n",
    "        }\n",
    "    \n",
    "    def train(self, train_loader, val_loader, epochs=150, lr=0.001):\n",
    "        \"\"\"Enhanced training with curriculum learning and advanced optimization\"\"\"\n",
    "        \n",
    "        # Advanced optimizer with better hyperparameters\n",
    "        optimizer = optim.AdamW(\n",
    "            self.model.parameters(), \n",
    "            lr=lr, \n",
    "            weight_decay=1e-4,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-8\n",
    "        )\n",
    "        \n",
    "        # More sophisticated learning rate scheduling\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            optimizer, T_0=20, T_mult=2, eta_min=1e-6\n",
    "        )\n",
    "        \n",
    "        # Enhanced early stopping\n",
    "        best_val_loss = float('inf')\n",
    "        best_cosine_sim = -1.0\n",
    "        patience_counter = 0\n",
    "        max_patience = 10\n",
    "        min_improvement = 1e-5\n",
    "        \n",
    "        # Tracking\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        cosine_similarities = []\n",
    "        loss_components = {'mse': [], 'cosine': [], 'huber': [], 'l1': [], 'correlation': []}\n",
    "        \n",
    "        print(\"Starting enhanced training...\")\n",
    "        print(f\"Model parameters: {sum(p.numel() for p in self.model.parameters()):,}\")\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training phase with curriculum learning\n",
    "            self.model.train()\n",
    "            train_loss = 0.0\n",
    "            epoch_loss_components = {k: 0.0 for k in loss_components.keys()}\n",
    "            \n",
    "            for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "                images = images.to(self.device, non_blocking=True)\n",
    "                targets = targets.to(self.device, non_blocking=True)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(images)\n",
    "                \n",
    "                # Advanced loss with epoch-dependent weighting\n",
    "                loss, components = self.advanced_loss_function(outputs, targets, epoch)\n",
    "                loss.backward()\n",
    "                \n",
    "                # Gradient clipping with adaptive norm\n",
    "                max_norm = 1.0 if epoch < 30 else 0.5\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=max_norm)\n",
    "                \n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "                \n",
    "                # Track loss components\n",
    "                for k, v in components.items():\n",
    "                    epoch_loss_components[k] += v\n",
    "                \n",
    "                if batch_idx % 50 == 0:\n",
    "                    print(f\"Epoch {epoch+1}, Batch {batch_idx}: Loss = {loss.item():.4f}\")\n",
    "            \n",
    "            # Update learning rate\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Validation phase with comprehensive metrics\n",
    "            self.model.eval()\n",
    "            val_loss = 0.0\n",
    "            total_cosine_sim = 0.0\n",
    "            total_l2_dist = 0.0\n",
    "            num_batches = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for images, targets in val_loader:\n",
    "                    images = images.to(self.device, non_blocking=True)\n",
    "                    targets = targets.to(self.device, non_blocking=True)\n",
    "                    \n",
    "                    outputs = self.model(images)\n",
    "                    loss, _ = self.advanced_loss_function(outputs, targets, epoch)\n",
    "                    val_loss += loss.item()\n",
    "                    \n",
    "                    # Multiple similarity metrics\n",
    "                    cosine_sim = F.cosine_similarity(outputs, targets).mean()\n",
    "                    l2_dist = torch.norm(outputs - targets, dim=1).mean()\n",
    "                    \n",
    "                    total_cosine_sim += cosine_sim.item()\n",
    "                    total_l2_dist += l2_dist.item()\n",
    "                    num_batches += 1\n",
    "            \n",
    "            # Average metrics\n",
    "            train_loss /= len(train_loader)\n",
    "            val_loss /= len(val_loader)\n",
    "            avg_cosine_sim = total_cosine_sim / num_batches\n",
    "            avg_l2_dist = total_l2_dist / num_batches\n",
    "            \n",
    "            # Average loss components\n",
    "            for k in epoch_loss_components:\n",
    "                epoch_loss_components[k] /= len(train_loader)\n",
    "                loss_components[k].append(epoch_loss_components[k])\n",
    "            \n",
    "            # Store history\n",
    "            train_losses.append(train_loss)\n",
    "            val_losses.append(val_loss)\n",
    "            cosine_similarities.append(avg_cosine_sim)\n",
    "            \n",
    "            print(f\"Epoch {epoch+1}/{epochs}:\")\n",
    "            print(f\"  Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "            print(f\"  Cosine Similarity: {avg_cosine_sim:.4f}, L2 Distance: {avg_l2_dist:.4f}\")\n",
    "            print(f\"  Learning Rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "            print(f\"  Loss Components - MSE: {epoch_loss_components['mse']:.4f}, \"\n",
    "                  f\"Cosine: {epoch_loss_components['cosine']:.4f}, \"\n",
    "                  f\"Huber: {epoch_loss_components['huber']:.4f}\")\n",
    "            \n",
    "            # Enhanced early stopping with multiple criteria\n",
    "            improvement = best_val_loss - val_loss\n",
    "            cosine_improvement = avg_cosine_sim > best_cosine_sim\n",
    "            \n",
    "            if (val_loss < best_val_loss and improvement > min_improvement) or cosine_improvement:\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                if avg_cosine_sim > best_cosine_sim:\n",
    "                    best_cosine_sim = avg_cosine_sim\n",
    "                    \n",
    "                patience_counter = 0\n",
    "                \n",
    "                # Save best model with comprehensive state\n",
    "                torch.save({\n",
    "                    'model_state_dict': self.model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'scheduler_state_dict': scheduler.state_dict(),\n",
    "                    'epoch': epoch,\n",
    "                    'val_loss': val_loss,\n",
    "                    'cosine_sim': avg_cosine_sim,\n",
    "                    'l2_dist': avg_l2_dist,\n",
    "                    'train_history': {\n",
    "                        'train_losses': train_losses,\n",
    "                        'val_losses': val_losses,\n",
    "                        'cosine_similarities': cosine_similarities,\n",
    "                        'loss_components': loss_components\n",
    "                    }\n",
    "                }, 'best_stolen_model.pth')\n",
    "                \n",
    "                print(f\"  ‚úì New best model saved (val_loss: {val_loss:.4f}, cosine: {avg_cosine_sim:.4f})\")\n",
    "                \n",
    "            else:\n",
    "                patience_counter += 1\n",
    "                print(f\"  ‚Üí No significant improvement (patience: {patience_counter}/{max_patience})\")\n",
    "                \n",
    "                if patience_counter >= max_patience:\n",
    "                    print(f\"\\nüõë Early stopping triggered at epoch {epoch+1}\")\n",
    "                    break\n",
    "                    \n",
    "                # Reduce learning rate if stuck\n",
    "                if patience_counter % 10 == 0:\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        param_group['lr'] *= 0.5\n",
    "                    print(f\"  üìâ Reduced learning rate to {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "            \n",
    "            print(\"-\" * 60)\n",
    "        \n",
    "        # Load best model\n",
    "        checkpoint = torch.load('best_stolen_model.pth')\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        \n",
    "        print(\"\\n‚úÖ Enhanced training completed!\")\n",
    "        print(f\"üìä Final Results:\")\n",
    "        print(f\"   Best validation loss: {best_val_loss:.4f}\")\n",
    "        print(f\"   Best cosine similarity: {best_cosine_sim:.4f}\")\n",
    "        print(f\"   Total epochs: {len(train_losses)}\")\n",
    "        \n",
    "        return checkpoint['train_history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:37:52.679064Z",
     "iopub.status.busy": "2025-06-24T20:37:52.678592Z",
     "iopub.status.idle": "2025-06-24T20:37:52.693486Z",
     "shell.execute_reply": "2025-06-24T20:37:52.692766Z",
     "shell.execute_reply.started": "2025-06-24T20:37:52.679043Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_stolen_data(filename=\"/kaggle/input/tml-assignment2-data/stolen_data_final.pickle\"):\n",
    "    \"\"\"Load stolen data from disk\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    return data['images'], data['representations']\n",
    "\n",
    "def load_session():\n",
    "    \"\"\"Load session data from JSON file\"\"\"\n",
    "    try:\n",
    "        with open('attack_session.json', 'r') as f:\n",
    "            session_data = json.load(f)\n",
    "        return session_data\n",
    "    except FileNotFoundError:\n",
    "        print(\"No session file found\")\n",
    "        return None\n",
    "\n",
    "def export_model_to_onnx():\n",
    "    \"\"\"Export the trained model to ONNX format with ONNX-compatible architecture\"\"\"\n",
    "    print(\"=== Exporting Enhanced Model to ONNX ===\")\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    try:\n",
    "        checkpoint = torch.load('best_stolen_model.pth', map_location=device, weights_only=False)\n",
    "        print(\"‚úì Loaded model checkpoint\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå Error: 'best_stolen_model.pth' not found!\")\n",
    "        return False\n",
    "    \n",
    "    # Create model and load weights\n",
    "    stolen_model = ImprovedStolenEncoder(input_dim=3, output_dim=1024)\n",
    "    stolen_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    stolen_model.eval()\n",
    "    stolen_model = stolen_model.cpu()\n",
    "    \n",
    "    print(\"‚úì Model loaded and moved to CPU for ONNX export\")\n",
    "    \n",
    "    # Create dummy input\n",
    "    dummy_input = torch.randn(1, 3, 32, 32)\n",
    "    print(f\"‚úì Created dummy input with shape: {dummy_input.shape}\")\n",
    "    \n",
    "    # Export to ONNX with optimized settings\n",
    "    onnx_path = 'stolen_model.onnx'\n",
    "    \n",
    "    try:\n",
    "        torch.onnx.export(\n",
    "            stolen_model,\n",
    "            dummy_input,\n",
    "            onnx_path,\n",
    "            export_params=True,\n",
    "            opset_version=11,  # Stable version with good compatibility\n",
    "            input_names=[\"x\"],\n",
    "            output_names=[\"output\"],\n",
    "            dynamic_axes={'x': {0: 'batch_size'}, 'output': {0: 'batch_size'}},\n",
    "            verbose=False,\n",
    "            do_constant_folding=True,  # Optimize the model\n",
    "            training=torch.onnx.TrainingMode.EVAL\n",
    "        )\n",
    "        print(\"‚úì ONNX export successful!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ONNX export failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Validate ONNX model\n",
    "    print(\"Validating ONNX model...\")\n",
    "    try:\n",
    "        ort_session = ort.InferenceSession(onnx_path)\n",
    "        \n",
    "        # Test with dummy input\n",
    "        test_input = np.random.randn(1, 3, 32, 32).astype(np.float32)\n",
    "        ort_inputs = {ort_session.get_inputs()[0].name: test_input}\n",
    "        ort_outputs = ort_session.run(None, ort_inputs)\n",
    "        output = ort_outputs[0][0]\n",
    "        \n",
    "        expected_shape = (1024,)\n",
    "        if output.shape != expected_shape:\n",
    "            print(f\"‚ùå Invalid output shape: {output.shape}, expected: {expected_shape}\")\n",
    "            return False\n",
    "            \n",
    "        print(f\"‚úì ONNX model validation successful!\")\n",
    "        print(f\"  Input shape: {test_input.shape}\")\n",
    "        print(f\"  Output shape: {output.shape}\")\n",
    "        print(f\"  Output range: [{output.min():.4f}, {output.max():.4f}]\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ONNX model validation failed: {e}\")\n",
    "        return False\n",
    "\n",
    "def submit_for_evaluation():\n",
    "    \"\"\"Submit the ONNX model for evaluation\"\"\"\n",
    "    print(\"\\n=== Submitting Enhanced Model for Evaluation ===\")\n",
    "    \n",
    "    TOKEN = \"96005201\"  # Replace with your actual token\n",
    "    onnx_path = 'stolen_model.onnx'\n",
    "    \n",
    "    # Load session info\n",
    "    try:\n",
    "        with open('/kaggle/input/tml-assignment2-data/attack_session.json', 'r') as f:\n",
    "            session_data = json.load(f)\n",
    "        seed = session_data.get('seed')\n",
    "        \n",
    "        if not seed:\n",
    "            print(\"‚ùå No seed found in session data!\")\n",
    "            return False\n",
    "            \n",
    "        print(f\"‚úì Using seed: {seed}\")\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå No session file found!\")\n",
    "        return False\n",
    "    \n",
    "    # Submit to evaluation server\n",
    "    try:\n",
    "        print(\"Submitting enhanced model to evaluation server...\")\n",
    "        with open(onnx_path, 'rb') as f:\n",
    "            response = requests.post(\n",
    "                \"http://34.122.51.94:9090/stealing\",\n",
    "                files={\"file\": f},\n",
    "                headers={\"token\": TOKEN, \"seed\": seed},\n",
    "                timeout=90\n",
    "            )\n",
    "        \n",
    "        print(f\"Response Status Code: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            result = response.json()\n",
    "            print(\"‚úÖ Submission successful!\")\n",
    "            print(f\"üìä Evaluation Result: {result}\")\n",
    "            \n",
    "            # Save submission result\n",
    "            submission_info = {\n",
    "                'submission_time': datetime.now().isoformat(),\n",
    "                'seed': seed,\n",
    "                'model_path': onnx_path,\n",
    "                'response': result,\n",
    "                'status': 'success',\n",
    "                'model_type': 'ImprovedStolenEncoder'\n",
    "            }\n",
    "            \n",
    "            with open('submission_result.json', 'w') as f:\n",
    "                json.dump(submission_info, f, indent=2)\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        else:\n",
    "            print(f\"‚ùå Submission failed with status {response.status_code}\")\n",
    "            print(f\"Response: {response.text}\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Submission failed: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:37:55.404396Z",
     "iopub.status.busy": "2025-06-24T20:37:55.404115Z",
     "iopub.status.idle": "2025-06-24T20:37:55.410830Z",
     "shell.execute_reply": "2025-06-24T20:37:55.410249Z",
     "shell.execute_reply.started": "2025-06-24T20:37:55.404377Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function with enhanced pipeline\"\"\"\n",
    "    print(\"=== Enhanced Model Stealing Pipeline ===\")\n",
    "    \n",
    "    # Step 1: Export enhanced model to ONNX\n",
    "    if not export_model_to_onnx():\n",
    "        print(\"‚ùå Enhanced model export failed.\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Submit for evaluation\n",
    "    if not submit_for_evaluation():\n",
    "        print(\"‚ùå Submission failed.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüéâ Enhanced pipeline completed successfully!\")\n",
    "    print(\"üìÅ Files created:\")\n",
    "    print(\"  - stolen_model.onnx (enhanced model)\")\n",
    "    print(\"  - submission_result.json (evaluation results)\")\n",
    "\n",
    "def train_enhanced_model():\n",
    "    \"\"\"Training function for the enhanced model\"\"\"\n",
    "    print(\"=== Training Enhanced Model ===\")\n",
    "    \n",
    "    # Load data\n",
    "    images, representations = load_stolen_data()\n",
    "    print(f\"Loaded {len(images)} images and {len(representations)} representations\")\n",
    "    \n",
    "    # Create enhanced model\n",
    "    model = ImprovedStolenEncoder(input_dim=3, output_dim=1024)\n",
    "    \n",
    "    # Create trainer\n",
    "    trainer = B4BRobustTrainer(model)\n",
    "    \n",
    "    # Create dataloaders with enhanced preprocessing\n",
    "    train_loader, val_loader = trainer.create_dataloader(\n",
    "        images, representations, batch_size=64, test_split=0.2\n",
    "    )\n",
    "    \n",
    "    # Train with enhanced strategy\n",
    "    history = trainer.train(\n",
    "        train_loader, val_loader, epochs=150, lr=0.001\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Enhanced training completed!\")\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-24T20:37:57.030063Z",
     "iopub.status.busy": "2025-06-24T20:37:57.029792Z",
     "iopub.status.idle": "2025-06-24T21:32:58.074022Z",
     "shell.execute_reply": "2025-06-24T21:32:58.073217Z",
     "shell.execute_reply.started": "2025-06-24T20:37:57.030046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # First train the enhanced model\n",
    "    print(\"Starting enhanced model training...\")\n",
    "    train_enhanced_model()\n",
    "    \n",
    "    # Then export and submit\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7633630,
     "sourceId": 12123137,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7734317,
     "sourceId": 12273278,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
